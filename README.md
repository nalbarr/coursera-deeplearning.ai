# coursera-deeplearning.ai

This is main repository to group the my course work as part of Coursera Deep Learning Specialization by [deeplearning.ai](https://www.coursera.org/specializations/deep-learning).

### Instructors
- Andrew Ng, Co-founder, Coursera, Adjunct Professor, Stanford University; formerly head of Baidu AI Group / Google Brain.
- Kian Katanforoosh
- Younes Bensouda Mourri

### Specialization
- Course 1:  [Neural Networks and Deep Learning](https://www.coursera.org/learn/neural-networks-deep-learning)
- Course 2:  [Improving Deep Neural Networks:  Hyperparameter tuning, Regularization and Optimization](https://www.coursera.org/learn/deep-neural-network)
- Course 3:  [Structuring Machine Learning Projects](https://www.coursera.org/learn/machine-learning-projects)
- Course 4:  [Convolutional Neural Network](https://www.coursera.org/learn/convolutional-neural-networks)
- Course 5:  [Sequence Models](https://www.coursera.org/learn/nlp-sequence-models)

### Eureka! moment
#### If you plan to only audit class, one thing to focus on
- Scan all the courses and review "Heros of Deep Learning" interviews.  Choose an area that you are passionate about or investigating and further research interviewee, current and past research.
- For example, Geoff Hinton is considered the grandfather of Deep Learning, so looking at some of the historical context on neural networks especially back propogation algorithms help set a solid conceptual foundation.  Also, he hints at his future research interests such as "Capsules Networks" and how he feels they will disrupt traditional convolutional neural network (CNN) architectures.

### Key Takeaways
- DL is about "representation learning" using deep (versus shallow) networks where there is decentralized topology and control. This is very different than human curated knowledge, rules or "feature engineering".
- AN's pedagogy and teaching style as bottom-up was effective for my next intellectual jump for DL; 
- NOTE: Starting to only learni *bottom-up* with Keras or Tensorflow to start is a distraction as you often do not understand what is happening with the DL "black box" versus layering from core programming language constructs and iterating to high level abstractions
- ANN architectures have certain "shapes" and model architecture "patterns".  You get more familiar when you try to solving similar problems or tasks and evaluat and visualize outcomes.
* DL research areas such as transfer learning are very exciting (as well as new and somewhat disturbing).  A specific example? Reusing cat image recognition model and tasks and actually be able to repurpose for something like radiology diagnosis!

### Course work
* [deeplearning.ai-course1](https://github.com/nalbarr/coursera-deeplearning.ai-course1)
* [deeplearning.ai-course2](https://github.com/nalbarr/coursera-deeplearning.ai-course2)
* [deeplearning.ai-course3](https://github.com/nalbarr/coursera-deeplearning.ai-course3)
* [deeplearning.ai-course4](https://github.com/nalbarr/coursera-deeplearning.ai-course4)
* [deeplearning.ai-course5](https://github.com/nalbarr/coursera-deeplearning.ai-course5)

### Related
* [Coursera, Machine Learning (Ng, Stanford)](https://www.coursera.org/learn/machine-learning)
* [my repo](https://github.com/nalbarr/coursera-stanford-machine-learning)
