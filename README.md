# coursera-deeplearning.ai
coursera-deeplearning.ai

This is main repository to group the my course work as part of Coursera Deep Learning Specialization by [deeplearning.ai](https://www.coursera.org/specializations/deep-learning).

Instructors:
- Andrew Ng, Co-founder, Coursera, Adjunct Professor, Stanford University; formerly head of Baidu AI Group / Google Brain.
- Kian Katanforoosh
- Younes Bensouda Mourri

### Course 1:  [Neural Networks and Deep Learning](https://www.coursera.org/learn/neural-networks-deep-learning)

### Course 2:  [Improving Deep Neural Networks:  Hyperparameter tuning, Regularization and Optimization](https://www.coursera.org/learn/deep-neural-network)

### Course 3:  [Structuring Machine Learning Projects](https://www.coursera.org/learn/machine-learning-projects)

### Course 4:  [Convolutional Neural Network](https://www.coursera.org/learn/convolutional-neural-networks)

### Course 5:  [Sequence Models](https://www.coursera.org/learn/nlp-sequence-models)

### Eureka! moment
#### If you plan to only audit class, one thing to focus on
* Scan all the courses and review "Heros of Deep Learning" interviews.  Choose an area that you are passionate about or investigating and further research interviewee, current and past research.
* For example, Geoff Hinton is considered the grandfather of Deep Learning, so looking at some of the historical context on neural networks especially back propogation algorithms help set a solid conceptual foundation.  Also, he hints at his future research interests such as "Capsules Networks" and how he feels they will disrupt traditional convolutional neural network (CNN) architectures.

### Key Takeaways
* DL is about "representation learning" using deep (versus shallow) networks where there is decentralized topology and control; this is very different than human curated knowledge or "feature engineering"
* AN's pedagogy and teaching style as bottom-up was effective for my next intellectual jump for DL; Learning with Keras or Tensorflow to start is a distraction as you often do not understand what is happening with the DL "black box" versus layering from core programming language constructs and iterating to high level abstractions
* ANN architectures have certain shapes and architecture patterns you get more exposure so when you try to solve the same problem and see outcomes and possible improvements.
* Hyper parameter tuning is still complex and highly dependent on core research trends.  I am still a bit uncomfortable here.  Assuming defaults, etc. can be challenging for regulated industries such as Healthcare.
* Transfer learning and other DL research areas are very exciting (as well as new and somewhat disturbing)  (e.g., reusing cat image recognition model and tasks and actually be able to repurpose for something like radiology diagnosis!!!)

### Course work
* [deeplearning.ai-course1](https://github.com/nalbarr/coursera-deeplearning.ai-course1)
* [deeplearning.ai-course2](https://github.com/nalbarr/coursera-deeplearning.ai-course2)
* [deeplearning.ai-course3](https://github.com/nalbarr/coursera-deeplearning.ai-course3)
* [deeplearning.ai-course4](https://github.com/nalbarr/coursera-deeplearning.ai-course4)
* deeplearning.ai-course5.  Starting 12/15/2017.

### Related

### Future Work
* Port key programming exercises into standalone Python
* Port key programming exercises into Scala notebook and compare and constrast