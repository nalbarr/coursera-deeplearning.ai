# coursera-deeplearning.ai
coursera-deeplearning.ai

This is main repository to group the my course work as part of Coursera Deep Learning Specialization by [deeplearning.ai](https://www.coursera.org/specializations/deep-learning).

### Instructors
- Andrew Ng, Co-founder, Coursera, Adjunct Professor, Stanford University; formerly head of Baidu AI Group / Google Brain.
- Kian Katanforoosh
- Younes Bensouda Mourri

### Specialization
- Course 1:  [Neural Networks and Deep Learning](https://www.coursera.org/learn/neural-networks-deep-learning)
- Course 2:  [Improving Deep Neural Networks:  Hyperparameter tuning, Regularization and Optimization](https://www.coursera.org/learn/deep-neural-network)
- Course 3:  [Structuring Machine Learning Projects](https://www.coursera.org/learn/machine-learning-projects)
- Course 4:  [Convolutional Neural Network](https://www.coursera.org/learn/convolutional-neural-networks)
- Course 5:  [Sequence Models](https://www.coursera.org/learn/nlp-sequence-models)

### Eureka! moment
#### If you plan to only audit class, one thing to focus on
- Scan all the courses and review "Heros of Deep Learning" interviews.  Choose an area that you are passionate about or investigating and further research interviewee, current and past research.
- For example, Geoff Hinton is considered the grandfather of Deep Learning, so looking at some of the historical context on neural networks especially back propogation algorithms help set a solid conceptual foundation.  Also, he hints at his future research interests such as "Capsules Networks" and how he feels they will disrupt traditional convolutional neural network (CNN) architectures.

### Key Takeaways
- DL is about "representation learning" using deep (versus shallow) networks where there is decentralized topology and control; this is very different than human curated knowledge or "feature engineering"
- AN's pedagogy and teaching style as bottom-up was effective for my next intellectual jump for DL; Learning with Keras or Tensorflow to start is a distraction as you often do not understand what is happening with the DL "black box" versus layering from core programming language constructs and iterating to high level abstractions
- ANN architectures have certain "shapes" and architecture "patterns"; you get more familiar when you try to solving identical or similar problems and measure and visualize outcomes.  Many of these are inspired by our own cognitive functions (e.g., vision, speech, language, etc.).  ANN variants of CNNs and RNNs tend to map to these use cases.
* DL research areas such as transfer learning are very exciting (as well as new and somewhat disturbing)  (e.g., reusing cat image recognition model and tasks and actually be able to repurpose for something like radiology diagnosis!!!).  There is a lot more to learn here !!!
* Hyper parameter tuning is still complex.  I am still a bit uncomfortable here as it seems very dependent on research popularized by NIPS or data science competitions and less by industry use cases that go through consensus process.  Assuming defaults, etc. can be challenging for regulated industries such as Healthcare.

### Course work
* [deeplearning.ai-course1](https://github.com/nalbarr/coursera-deeplearning.ai-course1)
* [deeplearning.ai-course2](https://github.com/nalbarr/coursera-deeplearning.ai-course2)
* [deeplearning.ai-course3](https://github.com/nalbarr/coursera-deeplearning.ai-course3)
* [deeplearning.ai-course4](https://github.com/nalbarr/coursera-deeplearning.ai-course4)
* [deeplearning.ai-course5] (https://github.com/nalbarr/coursera-deeplearning.ai-course5).

### Related
* Coursera, Machine Learning (Ng, Stanford) (https://www.coursera.org/learn/machine-learning), (https://github.com/nalbarr/coursera-stanford-machine-learning)

### Future Work
* Assess Generative Adversial Networks (GANs)
* Assess Reinforcement Learning (RL)
* Port key programming exercises into standalone Python
* Port key programming exercises into Scala notebook and compare and constrast
